
\section{Results}
\label{sec:results}
Table~\ref{summaryResults} summarizes the results of the RQs.  \todoMid{This table does not show anything about significance... I wonder if we could do something like $\rightarrow$ for no significance (just based on averages) and $\Rightarrow$ for significance... just a thought. We could do a test of two proportions for the Com column. Some entries will be n/a for match and compose}

\input{table/nodeCountTable}

\subsection{RQ1: Community Support}
Figure~\ref{table:nodeCount} presents the frequencies with which each representation appears in a regex pattern and in a project scraped from GitHub. Recall that the patters are all unique and could appear in multiple projects, hence the project support is used to show how pervasive the representation in across the whole community. For example, representation C1 matches when a custom character class uses ranges and it appears in 2,479 (18.2\%) of all the patterns but 810 (52.5\%) of the projects. Representation D1 appears in 367 (2.7\%) of the patterns but only 242 (15.7\%) of the projects. In contrast, representation T3 appears in 60 \emph{fewer} patterns but 26 \emph{more} projects, indicating that D1 is more concentrated in a few projects and T3 is more widespread across projects. 

Using the pattern frequency as a guide, we can create refactoring recommendations based on community frequency. For example, since C1 is more prevalent than C2, we could say that C2 is smelly since it could better conform to the community standard if expressed as C1. Thus, we might recommend a $C2 \Rightarrow C1$ refactoring. Table~\ref{summaryResults} presents these recommendations for each pair of representations within each equivalence class. The \emph{Comm} column is populated based on the findings of \emph{RQ1}. The findings for \emph{RQ2} and \emph{RQ3} are in the \emph{Match} and \emph{Compose} columns, respectively. 


\begin{table}[t]
\caption{Summary of Refactoring Directions \label{summaryResults}}
\begin{center}
\begin{tabular}{|c@{ }c | c  l l |} \hline
\multicolumn{2}{|c|}{\textbf{Pair}} & \textbf{Com} & \textbf{Match} & \textbf{Compose} \\ \hline \hline
C1 & C2 & $\Leftarrow$  & $\Leftarrow$ (E1) $\Rightarrow$ (E2,  E3) & $\Leftarrow$ (E1) $\Rightarrow$ (E2, E3)\\
C1 & C3 & $\Leftarrow$ & & \\
C1 & C4 & $\Leftarrow$ & $\equiv$ (E4) & $\Leftarrow$  (E4)\\
C1 & C5 & $\Leftarrow$ & $\Leftarrow$ (E5) & $\Rightarrow$ (E5) \\
C2 & C3 & $\Rightarrow$ & & \\
C2 & C4 & $\Leftarrow$ & $\Rightarrow$ (E6) & $\Rightarrow$ (E6)\\
C2 & C5 & $\Leftarrow$ & $\Rightarrow$ (E7, E8) & $\Rightarrow$ (E7, E8)\\
C3 & C4 & $\Leftarrow$ & & \\
C3 & C5 & $\Leftarrow$ & & \\
C4 & C5 & $\Leftarrow$ & & \\
\hline
D1 & D2 & $\Rightarrow$ & $\Leftarrow$ (E9)& $\Leftarrow$ (E9) \\
D1 & D3 & $\Rightarrow$ & $\Rightarrow$ (E10)& $\Rightarrow$ (E10) \\
D2 & D3 & $\Leftarrow$ & $\Rightarrow$ (E11) & $\Rightarrow$ (E11) \\
\hline
L1 & L2 & $\Rightarrow$ & & \\
L1 & L3 & $\Leftarrow$ & & \\
L2 & L3 & $\Leftarrow$ & $\Rightarrow$ (E12) & $\Rightarrow$ (E12)  \\
\hline 
S1 & S2 & $\Rightarrow$ & $\Leftarrow$ (E13) & $\Leftarrow$ (E13) \\
S1 & S3 & $\Leftarrow$ & & \\
S2 & S3 & $\Leftarrow$ & & \\
\hline 
T1 & T2 & $\Leftarrow$  & $\Leftarrow$ (E2)& $\Leftarrow$ (E2) \\
T1 & T3 & $\Leftarrow$ & $\Leftarrow$ (E14) & $\Rightarrow$ (E14)\\
T1 & T4 & $\Leftarrow$ & $\Leftarrow$ (E15, E8, E3) & $\Leftarrow$ (E15, E8, E3)\\
T2 & T3 & $\Leftarrow$ & & \\
T2 & T4 & $\Leftarrow$ & $\Leftarrow$ (E16) & $\Leftarrow$ (E16)\\
T3 & T4 & $\Leftarrow$ & & \\
\hline
%1 & 2 &  & & \\
%1 & 3 &  & & \\
%2 & 3 &  & & \\


\end{tabular}
\end{center}
\end{table}


\subsection{RQ2: Understandability via Matching}
Table~\ref{table:testedEdgesTable} shows average understandability values. 

\input{table/testedEdgesTable}


\subsection{RQ3: Understandability via Composition}

\subsection{RQ4: Overlap in Refactorings}


(for rough draft...)

Looks like M6 and M8 are the best meta-refactorings according to ANOVA.
If you peek at MTResults Processing.csv on google docs, M6 has the best refactoring...every OCTAL type should be converted to an OR or preferably a CCC.

M8 has a weak P value, but still ok in one case (0.12) and consistently says that 'aa*' should be written as 'a+'.

Looks like M0, M1, M2, M3 and M9 are very dependent on the regex chosen, so regex-specific refactorings like:
0.1401 \verb!&d([aeiou][aeiou])z'    &d([aeiou]{2})z'!
0.075   \verb![\t\r\f\n ]'    [\s]'!
0.1024  \verb![a-f]([0-9]+)[a-f]' [a-f](\d+)[a-f]'!
0.1271  \verb![\{][\$](\d+[.]\d)[}]'!
\verb!\\\{\\\$(\d+\.\d)\}'!
(from M0,M1,M2,M9 respectively)

have okay P-values and may indicate regex-specific refactorings, but do not indicate an overall trend for that type of refactoring.
Notice that M3 does not even have a strong p-value candidate, but this may be thrown off because of the very confusing regex chosen for CCC:
0.78    0.79
\verb!xyz[_\[\]`\^\\]'!    \verb!xyz[\x5b-\x5f]'!
which has a lot of escape characters, so that the hex group was easier to understand than the CCC.



Meanwhile M4,M5 and M7 have both ambiguous p-values and anova results.  But this is still a finding: that no refactoring is needed between things like:
\verb!(q4fab|ab)'! (\verb!(q4f){0,1}ab)'!
\verb!tri[abcdef]3'!   \verb!tri(a|b|c|d|e|f)3'!
\verb!&(\w+);'!    \verb!&([A-Za-z0-9_]+);'!
(from M4,M5,M7 respectively)

Although one refactoring from M5 might be of slight interest:
0.1196  FALSE   \verb!tri[a-f]3'!  \verb!tri(a|b|c|d|e|f)3'!

\todoMid{more data from the composition problems}
