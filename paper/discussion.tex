\section{Discussion}
\label{sec:discussion}
\subsection{Interpreting Results}
Some common sense: C1 is probably more common because it is equally readable and smaller.  Regex length is probably important for readability - the longest regex in the corpus is \todoNow{X} characters long...  Anyway C2 is comon but less readable.  C4 is somehwat less common to use defalut in CC - why?  C5 is rare, but marginally more readable than C2.  Not enough data or contrast to come to a conclusion about C3 - it is a catch-all?  D3 merits further exploration because it is the most readable but least common node in DBB group.  Intuitively, it seems that D2 may be more common because 0,1 is just a more common use case than an arbitrary range like 4, 25.  S1 is a compact representation, so probably better than S2.  S2 is over-weighted because of double-characters in regular words like foot.  In the T group, we have the strongest results and some important context to add: T1 is just the normal way of doing things, but the reason to use a hex or oct type literal is because some characters in a charset cannot be represented any other way, like invisible chars.  One main result of our work is to confirm that both in terms of readability and community, T4 is always much much worse than T2, so if invisible chars are required, there is never a case where octals should be used.  About T3 - initially we thought it would have an advantage over characters that need to be escaped, because slashes are hard on the eyes when reading regular expressions, but we found that this is not the case and that given a choice between the two, everyone always prefered T1 with slashes.  For L1, it's clear that this is a rare use case, and also that L3 is the most common  use case.  Patterns using star are secondary, helper patterns because they will trivially match anything, so they are less common.  But anyway...

\todoNow{in study section present choices about pairwise vs random selection for nodes.}
\subsection{Opportunities For Future Work}
\paragraph{Equivalence Class Models}
We looked at 5 equivalence classes, each with 3 to 5 nodes.  Future work could study this topic using richer models with more and/or better classes and nodes.  For example, in our treatment, we have looked at all ranges as equivalent, all defaults as equivalent, and relied on many such generalizations.  But the range \verb![a-f]! is likely to be more understandable for most people than a range like \verb![:-`]!. By creating a more granular model of equivalence classes, and making sure to carefully evaluate alternative representations of the most frequently used specific patterns (like \verb!\\s*! and \verb!.+!), many more strong and useful refactorings could be identified.

In addition to breaking our 5 groups into more specific nodes, future work could model refactorings outside of these groups.  We have not determined a list of all possible refactoring groups given the functional variety and significant number of features to consider, but we are aware of a few additional equivalence classes outside of our 5 groups, such as:
\begin{description}
\item[Single line option]  \verb!'''(.|\n)+'''! $\equiv$ \verb!(?s)'''(.)+'''!
\item[Multi line option]  \verb!(?m)G\n! $\equiv$ \verb!(?m)G$!
\item[Multi line option]  \verb!(?i)[a-z]! $\equiv$ \verb![A-Za-z]!
\item[Backreferences]  \verb!(X)q\1! $\equiv$ \verb!(?P<name>X)q\g<name>!
\item[Word Boundaries]  \verb!\bZ! $\equiv$ \verb!((?<=\w)(?=\W)|(?<=\W)(?=\w))Z!
\end{description}

We focused on refactorings within a group, treating groups as orthogonal to one another.  It would be interesting to see if there is some cooperation between pairs of edges in separate groups by applying more than one type of refactoring at once.

\paragraph{Understandability}
We identified and utilized three new ways to measure understandability of regexes: deciding if certain strings match or not, composing strings that are supposed to match, and measuring the frequency of a regex type in a community.  There are many more ways to approach understandability, such as deciding what content is captured by a regex, identifying all the matched substrings in a block of text, deciding which regexes in a set are equivalent, finding the minimum modification to some text so that a given regex will match it, and many more.  One of the most straightforward ways to address understandability is to directly ask software professionals which from a list of equivalent regexes they prefer and why.  It may also be meaningful to provide some code that exists around a regex as context.  The example regexes we used were inspired by real regexes, but at least one side of the refactoring was contrived and we did not focus on any specific community (the 1544 projects we obtained regexes from were randomly obtained).  If understandability measurements used regexes sampled from the codebase of a specific community(most frequently observed regexes, most buggy regexes, regexes on the hottest execution paths, etc.), and measured the understanding of programming professionals working in that community, then the measurements and the refactorings they imply would be more likely to have a direct and certain positive impact.

In another study, we did a survey where software professionals indicated that understandability of regexes they find in source code is a major pain point.  In this study, our participants indicated that they read about twice as many regexes as they compose.  What is the impact on maintainers, developers and contributors to open-source projects of not being able to understand a regex that they find in the code they are working with?  Presumably this is a frustrating experience - how much does a confusing regex slow down a software professional?  What bugs or other negative factors can be attributed to or associated with regexes that are difficult to understand?  How often does this happen and in what settings?  Future work could tailor an in-depth exploration of the overall costs of confusing regexes and the potential benefits of refactoring or other treatments for confusing regexes.

\paragraph{Regex Refactoring Applications}
Other opportunities exist to improve the understandability of regexes in existing code bases by looking for some of the less understandable regex representations, which can be thought of as antipatterns, and refactoring to the more common or understandable representations. Building migration libraries is another direction of future work to ease the manual burden of this process, similar in spirit to prior work on class library migration~\cite{Balaban:2005:RSC:1103845.1094832}.

Maintainers of code that is intentionally obfuscated for security purposes may want to develop regexes that they understand and then automatically transform them into the least understandable regex possible.

One fundamental concept that many users of regex struggle to learn is when to use regexes for simple parsing, and when to write a full-fledged parser (for example, when parsing HTML).  Regexes that are trying to parse HTML, XML or similar languages could be refactored not into a better regex, but into some code with an equivalent intention that does parsing much better.

Many organizations enforce coding standards in their repositories to ease understandability.
Presently, we are not aware of coding standards for regular expressions, but this work suggests that enforcing standard representations for various regex constructs could ease comprehension.  Besides comprehension, an organization may want to enforce standards for efficiency, or for compatibility with a regex analysis tool like Z3, HAMPI, BRICS or REX.

\subsection{Threats to Validity}

\subsubsection{Internal}
We measure understandability of regexes using two metrics, matching and composition. However, these measures may not reflect actual understanding of the regex behavior. For this reason, we chose to use two metrics and present the analysis in the context of reading and writing regexes, but the threat remains.

\todoMid{what about the threat of too few examples per node?  Didn't cover every edge.  Regex set is randomly collected online, not focused on any specific target audience.}

We treated unsure responses as omissions and did not count those against the participants. Thus, if a participant answered two strings correctly with match/not match, and marked the other three strings as unsure, then this was 2/2 correct, not 2/5.

\subsubsection{External}
Participants in our survey came from MTurk, which may not be representative of people who read and write regexes on a regular basis.

The regexes we used in the evaluation were inspired by those commonly found in Python code, which is just one language that has library support for regexes. Thus, we may have missed opportunities for other refactorings based on how programmers use regexes in other programming languages.

Our community analysis only focuses on the Python language. Note that because the vast majority of regex features are shared across most general programming languages (e.g., Java, C, C\#, or Ruby), a Python {pattern} will (almost always) behave the same when used in other languages, whereas a utilization is not universal in the same way (i.e., it may not compile in other languages, even with small modifications to function and flag names).
As an example, the {\tt re.MULTILINE} flag, or similar, is present in Python, Java, and C\#, but  the Python {\tt re.DOTALL} flag is not present in C\# though it has an equivalent flag in Java.
